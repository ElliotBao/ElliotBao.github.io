<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-60320583-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-60320583-2');
</script>

<title>Zeyang Bao - Home</title>
<link rel="stylesheet" type="text/css" href="style.css">

<script type="text/javascript" src="js/hidebib.js"></script>

</head>
<body>

<div class="section">
<h1>Zeyang Bao</h1>
</div>
<hr>

<div class="section">
<table>
  <tr valign="top"> <td style="width: 600px; vertical-align: top;">
  I'm an incoming University of California, Berkeley (UCB) EECS Meng Student.</br>
  Previously, I graduated from Rutgers University, New Brunswick with Mathematics and Computer Science majors (Highest Honor), where I fortunately work with
  <a href="http://eceweb1.rutgers.edu/~sw891/">Professor Wei, Sheng</a> and <a href="https://www.cs.rutgers.edu/people/professors/details/kang-li">Professor Li, Kang</a>. </br>
  I also have an exchange student experience in Hong Kong University of Science and Technology (HKUST) where I fortunately work with <a href="https://facultyprofiles.ust.hk/profiles.php?profile=kani-chen-makchen">Professor Chen, Kani</a>.
  <p><br></p>
  I'm interested in computer vision and cross-modal.
  <p><br></p>
  <p>
    <a href="javascript:toggleblock('email')">email</a> | <a href="https://github.com/elliotbao">github</a>  | <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-93.html">thesis</a> | <a href="CV_Zeyang Bao.pdf">cv</a>
  </p>
  <pre xml:space="preserve" id="email" style="font-size: 12px">

elliotbao AT {gmail.com}
  </pre>
  <script xml:space="preserve" language="JavaScript">
  hideblock('email');
  </script>
  </td>

  <td width="400"><img src="img.JPG" alt="My picture" height=250 align="right"/></td>
    </tr>
  </table>
</div>

<div class="section">
<h2> Publications </h2><br><div class="year_heading"><br>2021<hr width="220px" align="left"></div>
<!--------------------------------------------------------------------------->
<div class="paper" id="ieeevr2021">
<img class="paper" src="figures/ieeevr2021.png" />
<p> <strong style="color:red">[New]</strong> <b id="papertitle">LiveObj: Object Semantics-based Viewport Prediction for Live Mobile Virtual Reality Streaming</b> <br/> 
Xianglong Feng, <strong>Zeyang Bao</strong>, Sheng Wei <br/> 
VR, 2021 <strong>(Journal track, acceptance rate: 25/161 = 15.5%)</strong><br/> 
<a href="">pdf </a>  &nbsp <a href="javascript:toggleblock('neurips20audioAbs')">abstract </a>  &nbsp <a href="javascript:toggleblock('neurips20audioBib')">bibtex </a>  &nbsp <a href="">video </a>  &nbsp <a href="">code </a> </p>
<div class="papermeta" id="neurips20audioMeta">
<em id="neurips20audioAbs">Virtual reality (VR) video streaming (a.k.a., 360-degree video streaming) has been gaining popularity recently as a new form of multimedia providing the users with immersive viewing experience. However, the high volume of data for the 360-degree video frames creates significant bandwidth challenges. Research efforts have been made to reduce the bandwidth consumption by predicting and selectively streaming the user's viewports. However, the existing approaches require historical user or video data and cannot be applied to live streaming, the most attractive VR streaming scenario. We develop a live viewport prediction mechanism, namely LiveObj , by detecting the objects in the video based on their semantics. The detected objects are then tracked to infer the user's viewport in real time by employing a reinforcement learning algorithm. Our evaluations based on 48 users watching 10 VR videos demonstrate high prediction accuracy and significant bandwidth savings obtained by LiveObj . Also, LiveObj achieves real-time performance with low processing delays, meeting the requirement of live VR streaming.
</em>
<pre xml:space="preserve" id="neurips20audioBib">

  @ARTICLE{9393620,
    author={Feng, Xianglong and Bao, Zeyang and Wei, Sheng},
    journal={IEEE Transactions on Visualization and Computer Graphics}, 
    title={LiveObj: Object Semantics-based Viewport Prediction for Live Mobile Virtual Reality Streaming}, 
    year={2021},
    volume={27},
    number={5},
    pages={2736-2745},
    doi={10.1109/TVCG.2021.3067686}}
  </pre></td>
<script language="javascript" type="text/javascript" xml:space="preserve">
hideblock('neurips20audioAbs');
hideblock('neurips20audioBib');
</script>
</div>
</div>
<!--------------------------------------------------------------------------->

<!--------------------------------------------------------------------------->
<div class="paper" id="ieeeaivr2020">
<img class="paper" src="figures/aivr2020.png" />
<p>  <b id="papertitle">Exploring CNN-based Viewport Prediction for Live Virtual Reality Streaming</b> <br/> 
Xianglong Feng, <strong>Zeyang Bao</strong>, Wei Sheng <br/> 
AIVR, 2020 <br/> 
<a href="papers/IEEE AIVR.pdf">pdf </a>  &nbsp <a href="javascript:toggleblock('corl20vimeAbs')">abstract </a>  &nbsp <a href="javascript:toggleblock('corl20vimeBib')">bibtex </a>  &nbsp <a href="">video </a>  &nbsp <a href="https://github.com/sarahisyoung/Visual-Imitation-Made-Easy/">code </a> </p>
<div class="papermeta" id="corl20vimeMeta">
<em id="corl20vimeAbs"> Live virtual reality streaming (a.k.a., 360-degree video streaming) is gaining popularity recently with its rapid growth in the consumer market. However, the huge bandwidth required by delivering the 360-degree frames becomes the bottleneck, keeping this application from a wider range of deployment. Research efforts have been carried out to solve the bandwidth problem by predicting the user's viewport of interest and selectively streaming a part of the whole frame. However, currently most of the viewport prediction approaches cannot address the unique challenges in the live streaming scenario, where there is no historical user or video traces to build the prediction model. In this paper, we explore the opportunity of leveraging convolutional neural network (CNN) to predict the user's viewport in live streaming by modifying the workflow of the CNN application and the training/testing process. The evaluation results reveal that the CNN-based method could achieve a high prediction accuracy with low bandwidth usage and low timing overhead.</em>
<pre xml:space="preserve" id="corl20vimeBib">

  @INPROCEEDINGS{8942314,
    author={Feng, Xianglong and Bao, Zeyang and Wei, Sheng},
    booktitle={2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)}, 
    title={Exploring CNN-Based Viewport Prediction for Live Virtual Reality Streaming}, 
    year={2019},
    volume={},
    number={},
    pages={183-1833},
    doi={10.1109/AIVR46125.2019.00038}}
  </pre></td>
<script language="javascript" type="text/javascript" xml:space="preserve">
hideblock('corl20vimeAbs');
hideblock('corl20vimeBib');
</script>
</div>
</div>
<!--------------------------------------------------------------------------->
  
<!--------------------------------------------------------------------------->
<div class="paper" id="iclr20synergy">
<img class="paper" src="figures/aresty15th.JPG" />
<p><b id="papertitle">AI Based Running Simulation</b> <br/> 
<strong>Zeyang Bao</strong>, Timothy Yong, Kang Li <br/> 
Aresty, 2019 <br/> 
<a href="papers/Bao_Zeyang_arestyposter.pdf">pdf </a>  &nbsp <a href="javascript:toggleblock('iclr20synergyAbs')">abstract </a> </p>
<div class="papermeta" id="iclr20synergyMeta">
<em id="iclr20synergyAbs">
  Nowadays, the usage of robotics is becoming more widespread for different applications and environments. There is a need for low-cost robotics to become more useful in larger settings, and a variety of methods can be applied to accomplish this task, the most successful of
them being reinforcement learning (RL). The default RL algorithm used by the OpenAI for robotic environments is Proximal Policy Optimization (PPO), which has relatively good model convergence, but easily converges to a local optimum if the entropy coefficient is not parameterized correctly. We had hoped to use a new algorithm named Chained Q-Learning (CQL), which samples the dependency between different joints in order to reduce the action space, in order to quickly first find a semi-global optimum before optimizing with another policy gradient algorithm.
</em>
</td>
<script language="javascript" type="text/javascript" xml:space="preserve">
hideblock('iclr20synergyAbs');
hideblock('iclr20synergyBib');
</script>
</div>
</div>
<!--------------------------------------------------------------------------->

<!--------------------------------------------------------------------------->
<!--- TEMPLATE
<div class="paper" id="paperId">
  <img class="paper" title="X" src="images/X.png" />
  <p><b id="papertitle">Title</b> <br/>
  <strong>Shubham Tulsiani</strong>, Richard Tucker, Noah Snavely<br />
  ECCV, 2018<br />
  <a href="link">pdf</a>  &nbsp <a href="page">project page</a>  &nbsp <a href="javascript:toggleblock('paperIdAbs')">abstract</a> &nbsp <a href="javascript:toggleblock('paperIdBib')">bibtex</a>  &nbsp <a href="codelink">code</a> </p>

  <div class="papermeta" id="paperIdMeta">
  <em id="paperIdAbs">ABSTRACT</em></p>
  <pre xml:space="preserve" id="paperIdBib" style="font-size: 12px">
@inProceedings{
BIBTEX
}</pre></td>
  <script language="javascript" type="text/javascript" xml:space="preserve">
     hideblock('paperIdAbs');
     hideblock('paperIdBib');
  </script>
  </div>
</div>

-->
<!--------------------------------------------------------------------------->

</div>


<!--------------------------------------------------------------------------->

<div class="section">
<h2> Project</h2>

<div class="paper" id="iclr20synergy">
<img class="paper" src="figures/empty.png" />
<p><b id="papertitle">Jocket Competition Data Crawler and Prediction</b> <br/> 
<strong>Zeyang Bao</strong><br/> 
Aresty, 2019 <br/> 
<a href="papers/Bao_Zeyang_arestyposter.pdf">pdf </a>  &nbsp <a href="javascript:toggleblock('jockey')">abstract </a> &nbsp <a href="">code </a> </p>
<div class="papermeta" id="iclr20synergyMeta">
<em id="jockey">
  
</em>
</td>
<script language="javascript" type="text/javascript" xml:space="preserve">
hideblock('jockey');
</script>
</div>
</div>
</div>
<!--------------------------------------------------------------------------->


<!--------------------------------------------------------------------------->
<div class="section">
<h2> Experiece</h2>

<div class="paper" id="experience">
<table width="100%" valign="top" border="0" cellspacing="0" cellpadding="20">
<tr>
  <td width="200px" valign="top"><img src="figures/oppo.png" width="120" height="99" align="left" /></td>

<td  style="width: 700px; vertical-align: top">
<p> <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">
</a><a><b id="papertitle3">Computer Vision Research Intern</b></a><br />
<heading>OPPO Research Institute</heading><br />
<heading>2020.9 - 2021.3</heading><br />
<a href="javascript:toggleblock('oppo')">Details </a>  </p>
<em id="oppo">
  o Conducted experiments on applying Self-supervised & Weak-Supervised Learning algorithms on cross-modal task </br>
  o Extracted relations in raw text to build Knowledge Graph, improved accuracy of fuzzy query by +10% </br>
  o Built a large-scale cross-modal retrieval system, launched for over 2M users
</em>
<script language="javascript" type="text/javascript" xml:space="preserve">
  hideblock('oppo');
  </script>
</p>
<p><br/></p>
<p><br/></p>
</td>
</tr>
</table>
</div>
</div>
<!--------------------------------------------------------------------------->


<div class="section">
<h2> Patent</h2>

<div class="paper" id="teaching">
<table width="100%" valign="top" border="0" cellspacing="0" cellpadding="20">
<tr>
<!-- <td width="200px" valign="top"><img src="figures/compPhoto.jpg" width="68" height="99" align="left" /></td> -->

<td  style="width: 700px; vertical-align: top">
<p>
<a href=""><b id="papertitle3">[Under Review] Two Direction Explainable Cross-Modal System</b></a><br />
<head><strong>Zeyang Bao</strong></head></br>
<heading>China</heading>
</p>
<p><br/></p>
<p><br/></p>
</td>
</tr>
</table>
</div>
<p>Website inspired from <a href="https://shubhtuls.github.io/">here</a></p>
</div>
</body>
</html>
